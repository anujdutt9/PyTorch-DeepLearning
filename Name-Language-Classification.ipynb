{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import glob\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khoury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nahas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nazari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  Khoury\n",
       "1   Nahas\n",
       "2   Daher\n",
       "3  Gerges\n",
       "4  Nazari"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Visualize some data files\n",
    "# Arabic Names\n",
    "df = pd.read_csv('./data/names/Arabic.txt', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abdi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0   Abbas\n",
       "1   Abbey\n",
       "2  Abbott\n",
       "3    Abdi\n",
       "4    Abel"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Visualize some data files\n",
    "# English Names\n",
    "df = pd.read_csv('./data/names/English.txt', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0     Abel\n",
       "1  Abraham\n",
       "2     Adam\n",
       "3   Albert\n",
       "4   Allard"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Visualize some data files\n",
    "# French Names\n",
    "df = pd.read_csv('./data/names/French.txt', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create { Language: [Names] } Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_names = {}\n",
    "categories = []\n",
    "for fileName in glob.glob('./data/names/*'):\n",
    "    dictKey = fileName.split('/')[3].split('.')[0]\n",
    "    categories.append(dictKey)\n",
    "    txt = open(fileName, encoding='utf-8').read().strip().split('\\n')\n",
    "    categorical_names[dictKey] = txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abl', 'Adsit', 'Ajdrna', 'Alt', 'Antonowitsch']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_names['Czech'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Khoury', 'Nahas', 'Daher', 'Gerges', 'Nazari']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_names['Arabic'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abbas', 'Abbey', 'Abbott', 'Abdi', 'Abel']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_names['English'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Names to Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Names\n",
    "\n",
    "# For each letter in a name: Create a One Hot Vector\n",
    "# One hot Vector Size = [1 x num_letters], where num_letters => letters in English from [aA to zZ]\n",
    "\n",
    "# Get all Letters in English [aA to zZ]\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "\n",
    "def letterToTensor(letter=None):\n",
    "    # Initialize tensor with all Zeros and size [1 x num_letters]\n",
    "    letter_tensor = torch.zeros(1,len(all_letters))\n",
    "    # One Hot Encoding the letters in a Name\n",
    "    # In this Tensor, find the index where the letter in word exists in the all_letters and make that as \"1\"\n",
    "    letter_tensor[0][all_letters.find(letter)] = 1\n",
    "    # Returns a single tensor with One hot Vector values for all letters in a name\n",
    "    # ex. name=\"anuj\", letter_tensor: One hot vector with \"1\" where the name matches\n",
    "    return letter_tensor\n",
    "\n",
    "\n",
    "# To get One hot Vector for Complete Name, join the Ohe Hot Vectors for all letters in a name in a 2-D matrix\n",
    "# 2-D Matrix size: [name_length x batch_size x num_letters]\n",
    "def nameToTensor(name=None):\n",
    "    # Initialize Tensor with all Zeros and size [name_length x batch_size = 1 x num_letters]\n",
    "    name_tensor = torch.zeros(len(name), 1, len(all_letters))\n",
    "    # Enumerate through Name, get the tensor for each letter in name and create a final tensor of size [name_length x batch_size x num_letters]\n",
    "    for i, letter in enumerate(name):\n",
    "        name_tensor[i][0][all_letters.find(letter)] = 1\n",
    "    # Returns name_tensor containing OHE vector for a name\n",
    "    return name_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN Class\n",
    "class RNN(nn.Module):\n",
    "    # Initialize Variables and Layers\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        # Define Hidden Layer size: num of neurons in hidden layer\n",
    "        self.hidden_size = hidden_size\n",
    "        # Input to Hidden Layer\n",
    "        self.input_to_hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        # Input to Output Layer\n",
    "        self.input_to_output = nn.Linear(input_size + hidden_size, output_size)\n",
    "        # Softmax Activation at Output\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    # Forward Pass\n",
    "    def forward(self, inputs, hidden):\n",
    "        # Combined Input Layers\n",
    "        combined = torch.cat((inputs, hidden), 1)\n",
    "        # Hidden Layer\n",
    "        hidden = self.input_to_hidden(combined)\n",
    "        # Output Layer\n",
    "        output = self.input_to_output(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    # Define Initial Hidden Layer Initialized to all Zeros\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model\n",
    "# Input: number of letters [aA to zZ]\n",
    "# Hidden Layer: 128\n",
    "# Output Layer: Number of Language Categories\n",
    "rnn = RNN(input_size=len(all_letters), hidden_size=128, output_size=len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of RNN(\n",
       "  (input_to_hidden): Linear(in_features=185, out_features=128, bias=True)\n",
       "  (input_to_output): Linear(in_features=185, out_features=18, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check RNN Parameters\n",
    "rnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer:  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n",
      "\n",
      "Next Hidden Layer Tensor: \n",
      " tensor([[ 0.0933,  0.0366,  0.0113, -0.0077, -0.0378,  0.0181, -0.0009,  0.1203,\n",
      "          0.0029, -0.0109,  0.1033, -0.0596, -0.0840, -0.1123,  0.1310, -0.0475,\n",
      "          0.1449,  0.0561, -0.1230,  0.0413, -0.0065, -0.0036, -0.0036, -0.0720,\n",
      "         -0.0725,  0.0229, -0.1286, -0.1061,  0.1155,  0.0892,  0.0853,  0.0831,\n",
      "         -0.0892,  0.0511, -0.0854,  0.0561,  0.0416, -0.0444,  0.1031,  0.0897,\n",
      "          0.0403, -0.0237, -0.0391, -0.0175, -0.1019, -0.0239, -0.0284, -0.0116,\n",
      "          0.0649, -0.0304,  0.0099,  0.0384, -0.0309,  0.0186,  0.0761,  0.0100,\n",
      "          0.0243, -0.0318,  0.0371, -0.0380, -0.1278, -0.1046, -0.0181, -0.0272,\n",
      "          0.0156,  0.0267,  0.0993, -0.1100,  0.0568, -0.0934, -0.0029, -0.1201,\n",
      "          0.0035,  0.0184,  0.0457,  0.0351,  0.0331,  0.0120, -0.0915, -0.0479,\n",
      "          0.0978, -0.0276,  0.0137, -0.0681, -0.0020, -0.0259,  0.0114,  0.0340,\n",
      "          0.1042, -0.0100,  0.1359,  0.1090, -0.0068, -0.1036,  0.1158,  0.1284,\n",
      "         -0.0159,  0.0411, -0.0418, -0.0985,  0.0631, -0.0527, -0.0316,  0.0687,\n",
      "         -0.0592,  0.0811, -0.0077, -0.0211,  0.0948,  0.0052,  0.0043, -0.0192,\n",
      "         -0.0789,  0.1015, -0.0156, -0.0258,  0.0342, -0.1094,  0.0618, -0.0090,\n",
      "          0.1090,  0.0053,  0.0061, -0.0946, -0.1054, -0.0483,  0.0182,  0.0021]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "\n",
      "Output Tensor: \n",
      " tensor([[-2.9797, -3.0122, -2.8761, -2.8919, -2.8712, -2.7701, -2.9784, -2.8912,\n",
      "         -2.8213, -2.8062, -2.8687, -2.9020, -2.9682, -2.8932, -2.9380, -2.8805,\n",
      "         -2.9383, -2.7802]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test out the untrained rnn for a name\n",
    "input_tensor = nameToTensor(name=\"Albert\")\n",
    "# Define Input Hidden layer to first RNN Module\n",
    "# Initialized with all zeros and size [1, 128]\n",
    "hidden0 = torch.zeros(1, 128)\n",
    "print(\"Hidden layer: \",hidden0)\n",
    "# Get the output of First RNN module and the next hidden layer values\n",
    "output, next_hidden = rnn(input_tensor[0], hidden0)\n",
    "# Print sample output and next hidden layer\n",
    "print(\"\\nNext Hidden Layer Tensor: \\n\",next_hidden)\n",
    "print(\"\\nOutput Tensor: \\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get final language category from tensor of probabilities\n",
    "def predictedLanguage(output=None):\n",
    "    top_n, top_i = output.topk(k=1)\n",
    "    languageCategoryIndex = top_i[0].item()\n",
    "    return categories[languageCategoryIndex], languageCategoryIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vietnamese', 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the function\n",
    "predictedLanguage(output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to choose randomly\n",
    "def randomChoice(data=None):\n",
    "    return data[random.randint(0, len(data) - 1)]\n",
    "\n",
    "# Function to get Random Training Example\n",
    "def randomTrainingExample():\n",
    "    # Choose category randomly\n",
    "    category = randomChoice(data=categories)\n",
    "    # Get Names from Dictionary corresponding to the Category\n",
    "    names = randomChoice(data=categorical_names[category])\n",
    "    # Load category as Torch Tensor\n",
    "    category_tensor = torch.tensor([categories.index(category)], dtype=torch.long)\n",
    "    # Load names in chosen category as Torch Tensor\n",
    "    names_tensor = nameToTensor(name=names)\n",
    "    return category, names, category_tensor, names_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Russian \tname = Tsarevsky\n",
      "category = Vietnamese \tname = Lam\n",
      "category = Spanish \tname = Abasolo\n",
      "category = Irish \tname = Eoin\n",
      "category = Polish \tname = Lawniczak\n",
      "category = Russian \tname = Vilyunas\n",
      "category = Russian \tname = Raihelson\n",
      "category = Greek \tname = Papoutsis\n",
      "category = Korean \tname = Hyun \n",
      "category = Greek \tname = Koustoubos\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    category, names, category_tensor, names_tensor = randomTrainingExample()\n",
    "    print('category =', category, '\\tname =', names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Criteria\n",
    "criteria = nn.NLLLoss()\n",
    "\n",
    "# Learning Rate\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(category_tensor=None, names_tensor=None):\n",
    "    # Initialize RNN Hidden Layer\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    # Clear all Gradients\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    # For names in names_tensor, get output and next hidden layer \n",
    "    for i in range(names_tensor.size()[0]):\n",
    "        output, hidden = rnn(names_tensor[i], hidden)\n",
    "\n",
    "    # Calculate Loss and Backpropagate it\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "        \n",
    "    # Return Output of RNN i.e. the Predicted Category and the Loss value\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
