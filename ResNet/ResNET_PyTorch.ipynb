{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNET-PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEkm31AbKkqw",
        "colab_type": "text"
      },
      "source": [
        "# ResNet Implementation in PyTorch\n",
        "\n",
        "In this notebook, we'll be implementing the ResNet model uisng PyTorch.\n",
        "\n",
        "Paper: [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "## Why ResNet?\n",
        "\n",
        "We know that as we develop deeper neural networks, we usually face the problem of Vanishing gradients i.e. as we go down the layers of a deep neural network, the gradients during the backpropagation process keeps getting smaller and smaller due to which after some time, some of the neurons might not even fire leading to poor training of the neural network.\n",
        "\n",
        "This problem has been addressed by using various techniques like Normalizing Initializations, adding Intermediate Normalization layers etc.\n",
        "\n",
        "Even after using the abovesaid solutions, the training accuracy for the deeper neural netowrks gets saturated after some time. Even adding more layers does not helps with the training.\n",
        "\n",
        "ResNet architecture was developed to solve this problem.\n",
        "\n",
        "## Building Block\n",
        "\n",
        "The ResNet architecture has a building block which is shown as below:\n",
        "\n",
        "![building_block](https://miro.medium.com/max/1140/1*D0F3UitQ2l5Q0Ak-tjEdJg.png)\n",
        "\n",
        "Let us understand this block in detail.\n",
        "\n",
        "### Residual Function Intuition\n",
        "1. In this block architecture, we have the Input \"x\" which is usually an image.\n",
        "\n",
        "2. This is then fed into the first layer, say a \"2D Convolution\" layer.\n",
        "\n",
        "3. After that, we add a Batch Normalization Layer and apply ReLU activation.\n",
        "\n",
        "The output of this activation is represented as below:\n",
        "\n",
        "```\n",
        "Residual Function\n",
        "F(x) := H(x) - x        ..(1)\n",
        "\n",
        "where,\n",
        "x: Input to the building block\n",
        "H(x): Learned underlying mapping\n",
        "F(x): Residual Function\n",
        "```\n",
        "\n",
        "This output looks different from a normal convolutional neural network architecure as here instead of learning about the input \"x\", we are trying to learn the underlying mapping H(x) using the stacked layers of the building block.\n",
        "\n",
        "If we hypothesizes that multiple nonlinear layers can asymptotically approximate complicated functions, then it is equivalent to hypothesize that they can asymptotically approximate the residual functions, i.e., H(x) − x.\n",
        "\n",
        "So rather than expect stacked layers to approximate H(x), we\n",
        "explicitly let these layers approximate a residual function F(x) := H(x) − x. The original function at the output (before activation) thus becomes F(x)+x.\n",
        "\n",
        "Hence, the output of this layer is represented by F(x) in equation (1) which represents the residual mapping.\n",
        "\n",
        "### Output Function Intuition\n",
        "4. Once we get the residual mapping from the first layer, then this output is used as input to the second layer consisting of a \"2D Convolution\" operation followed by \"Batch Normalization\" layer.\n",
        "\n",
        "5. Now before applying the ReLU activation to the output of the second layer, we add the Input \"x\" to the output of the second layer. This is represented as follows:\n",
        "\n",
        "```\n",
        "Recasting the output to Original Mapping\n",
        "y = F(x) + x           ..(2)\n",
        "\n",
        "where,\n",
        "F(x): Output of First Layer.\n",
        "x: Input to this building block.\n",
        "y: Output of the building block.\n",
        "```\n",
        "\n",
        "Adding the input to the output of the final layer in the building block before applying the activation function helps us to recast the underlying mapping F(x) in equation (1) to the original mapping represented by y in equation (2).\n",
        "\n",
        "Since, we add (element wise addition) the original Input as an Identity, it doesn't adds any new parameters to the neural network, as it's not part of the final Weight Matrix, as well as doesn't adds any extra complexity.\n",
        "\n",
        "## Building Block Formalization\n",
        "\n",
        "We adopt residual learning to every few stacked layers. The building block is defined as the following:\n",
        "\n",
        "```\n",
        "y = F(x, {Wi}) + x     ..(3)\n",
        "\n",
        "where,\n",
        "x: Input Vector\n",
        "y: Output Vector\n",
        "F(x, {Wi}): Function representing the residual mapping to be learned\n",
        "```\n",
        "\n",
        "For example, for the image in the previous section, if we represent the first weight layer by W1 and the second weight layer by W2, the Output Vector can be represented as:\n",
        "\n",
        "```\n",
        "y = W2 * ReLu(W1 * x)   ..(4)\n",
        "```\n",
        "\n",
        "Additionally, there could be cases where we need to perform dimensionality mapping. For example, going from one layer with 64 filters to another layer with 128 filters, we need to make sure the dimensions of the output of the previous layer matches the input of the next layer.\n",
        "We know that the final output vector \"y\" is achieved by the elementwise addition of the learned residual mapping and the identity mapping from the shortcut connection.\n",
        "To solve the problem of matching the dimensions, we perform a linear projection \"Ws\" by the shortcut connections to match the dimensions.\n",
        "\n",
        "Hence, the output vector in the equation (3) is changed to the following:\n",
        "\n",
        "```\n",
        "y = F(x, {Wi}) + Wsx    ..(5)\n",
        "\n",
        "where,\n",
        "Ws: is usually a 1x1 convolution operation\n",
        "```\n",
        "\n",
        "## Bottleneck Block\n",
        "\n",
        "The basic building block works well for small number of layers in the architecture but when we scale the number of layers upto like 50/101/152 and so on, we use a different variant of the building block for improving the training process.\n",
        "\n",
        "The Bottleneck Block looks like below:\n",
        "\n",
        "![Bottleneck Block](https://i.stack.imgur.com/kbiIG.png)\n",
        "\n",
        "The above figure shows a comparison between the Basic Block and the Bottleneck Block.\n",
        "\n",
        "In the Bottleneck Block, for each residual function F, we use a stack of 3 layers instead of 2 as shown in the figure above. The three layers are 1×1, 3×3, and 1×1 convolutions, where the 1×1 layers are responsible for reducing and then increasing (restoring) dimensions, leaving the 3×3 layer a bottleneck with smaller input/output dimensions.\n",
        "\n",
        "So, now that we have covered most of the basics of the ResNet architecure, it's time to implement them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzSFvNicIj7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgElP0kBJ5N0",
        "colab_type": "text"
      },
      "source": [
        "# Building Block a.k.a Residual Block\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHjfnZARJOUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic ResNet Block\n",
        "class ResidualBlock(nn.Module):\n",
        "  # expansion: Block expansion parameter in order to increase the out_channels if needed\n",
        "  expansion= 1\n",
        "\n",
        "  # Constructor\n",
        "  # The Building Block requires the following:\n",
        "  # Input Dimension, Output Dimension, Stride\n",
        "  def __init__(self, input_channels, output_channels, stride=1, dim_change=None):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    # First Layer\n",
        "    self.conv1 = nn.Conv2d(in_channels= input_channels,\n",
        "                           out_channels= output_channels,\n",
        "                           kernel_size= 3,\n",
        "                           stride= stride,\n",
        "                           padding=1)\n",
        "    \n",
        "    # Batch Normalization 1\n",
        "    self.bn1 = nn.BatchNorm2d(output_channels)\n",
        "\n",
        "    # Second Layer\n",
        "    self.conv2 = nn.Conv2d(in_channels= output_channels,\n",
        "                           out_channels= output_channels,\n",
        "                           kernel_size= 3,\n",
        "                           stride= 1,\n",
        "                           padding=1)\n",
        "    \n",
        "    # Batch Normalization 2\n",
        "    self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "\n",
        "    # Dimension Change Flag\n",
        "    # Dimension change is required for the output of the current block if the \n",
        "    # number of channels in the next block are more than the current block.\n",
        "    self.dim_change = dim_change\n",
        "    \n",
        "  # Forward Pass\n",
        "  def forward(self, x):\n",
        "    # Residue\n",
        "    res = x\n",
        "    # F(x) := H(x) - x\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "\n",
        "    # Check if a dimension change is required\n",
        "    if self.dim_change is not None:\n",
        "      res = self.dim_change(res)\n",
        "    \n",
        "    # y = F(x) + x\n",
        "    out += res\n",
        "    out = F.relu(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S0cF8qVHo-T",
        "colab_type": "text"
      },
      "source": [
        "# Bottleneck Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-6mq1RdeMhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bottleneck Block\n",
        "class BottleNeckBlock(nn.Module):\n",
        "  # expansion: Block expansion parameter in order to increase the out_channels if needed\n",
        "  # In the Bottleneck Block, the last 1x1 Conv layer has 4 times the number of channels\n",
        "  # as compared to the previous layer\n",
        "  expansion= 4\n",
        "\n",
        "  # Constructor\n",
        "  # The Building Block requires the following:\n",
        "  # Input Dimension, Output Dimension, Stride\n",
        "  def __init__(self, input_channels, output_channels, stride=1, dim_change=None):\n",
        "    super(BottleNeckBlock, self).__init__()\n",
        "\n",
        "    # 1x1 Convolution\n",
        "    self.conv1 = nn.Conv2d(in_channels= input_channels,\n",
        "                           out_channels= output_channels,\n",
        "                           kernel_size= 1,\n",
        "                           stride= 1)\n",
        "    \n",
        "    # Batch Normalization 1\n",
        "    self.bn1 = nn.BatchNorm2d(output_channels)\n",
        "    \n",
        "    # 3x3 Convolution\n",
        "    self.conv2 = nn.Conv2d(in_channels= output_channels,\n",
        "                           out_channels= output_channels,\n",
        "                           kernel_size= 3,\n",
        "                           stride= stride,\n",
        "                           padding=1)\n",
        "    \n",
        "    # Batch Normalization 2\n",
        "    self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "\n",
        "    # 1x1 Convolution\n",
        "    # Mutiply output channels with expansion to increase the output dimension\n",
        "    self.conv3 = nn.Conv2d(in_channels= output_channels,\n",
        "                           out_channels= output_channels * self.expansion,\n",
        "                           kernel_size= 1)\n",
        "    \n",
        "    # Batch Normalization 3\n",
        "    self.bn3 = nn.BatchNorm2d(output_channels * self.expansion)\n",
        "\n",
        "    # Dimension Change Flag\n",
        "    # Dimension change is required for the output of the current block if the \n",
        "    # number of channels in the next block are more than the current block.\n",
        "    self.dim_change = dim_change\n",
        "\n",
        "  # Forward Pass\n",
        "  def forward(self, x):\n",
        "    res = x\n",
        "\n",
        "    # 1x1 Layer 1: Input [Reduce Size]\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "    # 3x3 Conv Layer\n",
        "    out = F.relu(self.bn2(self.conv2(out)))\n",
        "\n",
        "    # 1x1 Layer 2 : Output [Expand Size]\n",
        "    out = self.bn3(self.conv3(out))\n",
        "\n",
        "    # Check if dimension change is required\n",
        "    if self.dim_change is not None:\n",
        "      res = self.dim_change(res)\n",
        "    \n",
        "    # Add Shortcut connect to get output\n",
        "    out += res\n",
        "    out = F.relu(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJVfIQ_6tiXt",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the basic blocks, we just need to bring them together to form the network as shown below:\n",
        "\n",
        "![ResNet34](https://raw.githubusercontent.com/floydhub/imagenet/master/images/resnet.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr5LOJVCHJQ0",
        "colab_type": "text"
      },
      "source": [
        "# ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbRJH6hf4x4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ResNet Architecture\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_layers, num_classes=None):\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    # Input Layer\n",
        "    self.input_channels = 64\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "    # 2nd block Layers\n",
        "    # buildingBlock: which block to use; Residual Block or Bottleneck Block\n",
        "    # num_channels: number of channels per layer in the block\n",
        "    # num_layers: number of blocks per block layer\n",
        "    self.layer1 = self._layer(buildingBlock=block, num_channels=64, num_layers=num_layers[0], stride=1)\n",
        "\n",
        "    # 3rd block Layers\n",
        "    self.layer2 = self._layer(buildingBlock=block, num_channels=128, num_layers=num_layers[1], stride=2)\n",
        "\n",
        "    # 4th block layers\n",
        "    self.layer3 = self._layer(buildingBlock=block, num_channels=256, num_layers=num_layers[2], stride=2)\n",
        "\n",
        "    # 5th block layers\n",
        "    self.layer4 = self._layer(buildingBlock=block, num_channels=512, num_layers=num_layers[3], stride=2)\n",
        "\n",
        "    # Avg Pooling layer\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size= 4, stride= 1)\n",
        "    \n",
        "    # Output Layer\n",
        "    # Fully connected Layer\n",
        "    self.fc = nn.Linear(in_features= 512 * block.expansion, out_features= num_classes)\n",
        "\n",
        "  def _layer(self, buildingBlock, num_channels, num_layers, stride=1):\n",
        "    dim_change = None\n",
        "\n",
        "    # Check if dimension changes i.e. if the stride of the next block is > 1\n",
        "    # or if the number of channels in the next block are more than the current block\n",
        "    if (stride != 1) or (num_channels != self.input_channels * buildingBlock.expansion):\n",
        "      dim_change = nn.Sequential(\n",
        "                              # Perform 1x1 Convolution on the Input i.e. x and increase it's dimension to match\n",
        "                              # the number of channels in the next block input.\n",
        "                              # Ex. going from block 1 with channels 64 to block 2 with channels 128\n",
        "                               nn.Conv2d(in_channels= self.input_channels,\n",
        "                                         out_channels= num_channels * buildingBlock.expansion,\n",
        "                                         kernel_size= 1,\n",
        "                                         stride= stride),\n",
        "                               # Apply Batch Normalization to that\n",
        "                               nn.BatchNorm2d(num_features= num_channels * buildingBlock.expansion))\n",
        "\n",
        "    # Form the Number of Block Layers equal to \"num_layers\" i.e. how many times the\n",
        "    # selected block is repeatedly stacked\n",
        "    # Create a Sequential Model with layers of the block\n",
        "    net_layers = []\n",
        "    # Input Layer of each Block\n",
        "    # If the dimenion change is required, it's required at the input layer block\n",
        "    net_layers.append(buildingBlock(self.input_channels, num_channels, stride=stride, dim_change=dim_change))\n",
        "    # Update Input Channels\n",
        "    self.input_channels = num_channels * buildingBlock.expansion\n",
        "\n",
        "    for i in range(1, num_layers):\n",
        "      # Append rest of the Blocks in the layer\n",
        "      net_layers.append(buildingBlock(self.input_channels, num_channels))\n",
        "      # Update the Input Channels\n",
        "      self.input_channels = num_channels * buildingBlock.expansion\n",
        "    \n",
        "    return nn.Sequential(*net_layers)\n",
        "\n",
        "  # Forward Pass\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    \n",
        "    # Stack up Layers of Blocks\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    # Average pool\n",
        "    x = F.avg_pool2d(x, 4)\n",
        "\n",
        "    # Convert Output from 3D to 2D\n",
        "    x = x.view(x.size(0), -1)\n",
        "\n",
        "    # Get the Output\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNI0LiOtuK2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the image transform\n",
        "# The output of torchvision datasets are PILImage images of range [0, 1]. \n",
        "# We transform them to Tensors of normalized range [-1, 1].\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM3kb5ieuPlz",
        "colab_type": "code",
        "outputId": "547934d4-6d1c-46d4-9f10-7af72d0805ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load Training Data\n",
        "train_data = torchvision.datasets.CIFAR10(root='./cifar_data/', train=True, download=True, transform=transform)\n",
        "\n",
        "# Load Test Data\n",
        "test_data = torchvision.datasets.CIFAR10(root='./cifar_data/', train=False, download=True, transform=transform)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAdKnesBuRyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Train Data Loader\n",
        "trainLoader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True, num_workers=3)\n",
        "\n",
        "# Create Test Data Loader\n",
        "testLoader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False, num_workers=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py4zNm37uhWr",
        "colab_type": "code",
        "outputId": "a3eaca22-07c5-43e4-b817-72dbca6b5c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define the Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wzFriqZCa7N",
        "colab_type": "text"
      },
      "source": [
        "# ResNet Architectures\n",
        "\n",
        "The below image shows various ResNet model Architectures with their configurations.\n",
        "\n",
        "![ResNet Architectures](https://neurohive.io/wp-content/uploads/2019/01/resnet-architectures-34-101.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6IOf9GOuqqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define ResNet Architectures\n",
        "# ResNet-8\n",
        "# model = ResNet(block= ResidualBlock,\n",
        "#                num_layers= [2, 2, 1, 1],\n",
        "#                num_classes=10)\n",
        "\n",
        "# ResNet-18\n",
        "model = ResNet(block= ResidualBlock,\n",
        "               num_layers= [2, 2, 2, 2],\n",
        "               num_classes=10)\n",
        "\n",
        "# ResNet-34\n",
        "# model = ResNet(block= ResidualBlock,\n",
        "#                num_layers= [3, 4, 6, 3],\n",
        "#                num_classes=10)\n",
        "\n",
        "# ----- More number of layers call for Bottleneck Block ------\n",
        "#ResNet-50\n",
        "# model = ResNet(block= BottleNeckBlock,\n",
        "#                num_layers= [3, 4, 6, 3],\n",
        "#                num_classes=10)\n",
        "\n",
        "# ResNet-101\n",
        "# model = ResNet(block= BottleNeckBlock,\n",
        "#                num_layers= [3, 4, 23, 3],\n",
        "#                num_classes=10)\n",
        "\n",
        "# ResNet-152\n",
        "# model = ResNet(block= BottleNeckBlock,\n",
        "#                num_layers= [3, 8, 36, 3],\n",
        "#                num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a3qsaB2ybn4",
        "colab_type": "code",
        "outputId": "4526a3eb-4b8e-4d5b-ebd9-7f0716525759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Send Model to Device\n",
        "model.to(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dim_change): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dim_change): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (dim_change): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1vGm6w8xbFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Criteria\n",
        "loss_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(),\n",
        "                      lr=0.02,\n",
        "                      momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSr6frI_HD-w",
        "colab_type": "text"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IGUqWIhyrPO",
        "colab_type": "code",
        "outputId": "18574107-1c22-46c1-c044-c8e6e1d66df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the Model\n",
        "Epochs = 30\n",
        "\n",
        "test_loss = 0\n",
        "train_losses, test_losses = [], []\n",
        "test_accuracy = []\n",
        "\n",
        "for epoch in range(Epochs):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, batch in enumerate(trainLoader, 0):\n",
        "    # Load data in batches\n",
        "    images, labels = batch\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Zero the Optimizer Gradient Values\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Define Model output\n",
        "    prediction = model(images)\n",
        "    \n",
        "    # Define Loss\n",
        "    loss = loss_criterion(prediction, labels)\n",
        "    \n",
        "    # Do backward Propagation of gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # Take one step for optimizer\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Capture Loss\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    # Print Loss and Accuracy\n",
        "    if i%100 == 0:\n",
        "        print(\"Epoch: {0}\\t i: {1}\\t Loss: {2}\".format(epoch+1, i+1, running_loss/1000))\n",
        "        # Reset Running Loss\n",
        "        running_loss = 0.0\n",
        "  \n",
        "  correctPredictions = 0\n",
        "  totalPredictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batches in testLoader:\n",
        "      images, labels = batches\n",
        "      images,labels = images.to(device), labels.to(device)\n",
        "      prediction = model(images)\n",
        "      # Get test loss\n",
        "      test_loss += loss_criterion(prediction, labels)\n",
        "      # Get Index of output class with max probability\n",
        "      _, prediction = torch.max(prediction.data, 1)\n",
        "      totalPredictions += labels.size(0)\n",
        "      correctPredictions += (prediction==labels).sum().item()\n",
        "    \n",
        "    test_accuracy.append(correctPredictions/totalPredictions)\n",
        "    train_losses.append(running_loss/len(trainLoader))\n",
        "    test_losses.append(test_loss/len(testLoader))\n",
        "\n",
        "    print(\"\\n-----------------------------\\n\")\n",
        "    print(\"Epoch: {0}\\t Accuracy: {1}%\".format(epoch+1, str((correctPredictions/totalPredictions)*100)))\n",
        "    print(\"\\n-----------------------------\\n\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\t i: 1\t Loss: 0.002395519733428955\n",
            "Epoch: 1\t i: 101\t Loss: 0.17706588637828827\n",
            "Epoch: 1\t i: 201\t Loss: 0.13703893494606018\n",
            "Epoch: 1\t i: 301\t Loss: 0.1151311149597168\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 1\t Accuracy: 66.47%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 2\t i: 1\t Loss: 0.0009264751672744752\n",
            "Epoch: 2\t i: 101\t Loss: 0.08588962823152542\n",
            "Epoch: 2\t i: 201\t Loss: 0.08031427097320556\n",
            "Epoch: 2\t i: 301\t Loss: 0.07854723250865936\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 2\t Accuracy: 75.62%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 3\t i: 1\t Loss: 0.0004952543675899505\n",
            "Epoch: 3\t i: 101\t Loss: 0.056114547073841094\n",
            "Epoch: 3\t i: 201\t Loss: 0.05785358244180679\n",
            "Epoch: 3\t i: 301\t Loss: 0.057484657764434816\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 3\t Accuracy: 78.53%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 4\t i: 1\t Loss: 0.000651563048362732\n",
            "Epoch: 4\t i: 101\t Loss: 0.04006990498304367\n",
            "Epoch: 4\t i: 201\t Loss: 0.04200382140278816\n",
            "Epoch: 4\t i: 301\t Loss: 0.043351623103022575\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 4\t Accuracy: 81.15%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 5\t i: 1\t Loss: 0.0002457484155893326\n",
            "Epoch: 5\t i: 101\t Loss: 0.026824389830231665\n",
            "Epoch: 5\t i: 201\t Loss: 0.029274854868650436\n",
            "Epoch: 5\t i: 301\t Loss: 0.032393860831856726\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 5\t Accuracy: 80.97999999999999%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 6\t i: 1\t Loss: 0.00014013847708702087\n",
            "Epoch: 6\t i: 101\t Loss: 0.016856684267520905\n",
            "Epoch: 6\t i: 201\t Loss: 0.01923498960584402\n",
            "Epoch: 6\t i: 301\t Loss: 0.022848947316408158\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 6\t Accuracy: 81.8%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 7\t i: 1\t Loss: 0.00012541082501411438\n",
            "Epoch: 7\t i: 101\t Loss: 0.01194756132736802\n",
            "Epoch: 7\t i: 201\t Loss: 0.013107708401978016\n",
            "Epoch: 7\t i: 301\t Loss: 0.01549195347726345\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 7\t Accuracy: 81.03%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 8\t i: 1\t Loss: 9.788914024829865e-05\n",
            "Epoch: 8\t i: 101\t Loss: 0.008622322266921402\n",
            "Epoch: 8\t i: 201\t Loss: 0.0097186812274158\n",
            "Epoch: 8\t i: 301\t Loss: 0.010631553627550602\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 8\t Accuracy: 81.66%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 9\t i: 1\t Loss: 0.00011022110283374787\n",
            "Epoch: 9\t i: 101\t Loss: 0.005900406364351511\n",
            "Epoch: 9\t i: 201\t Loss: 0.007054256996139884\n",
            "Epoch: 9\t i: 301\t Loss: 0.008311409376561642\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 9\t Accuracy: 81.64%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 10\t i: 1\t Loss: 2.6977868750691414e-05\n",
            "Epoch: 10\t i: 101\t Loss: 0.005249320678412914\n",
            "Epoch: 10\t i: 201\t Loss: 0.004628198727965355\n",
            "Epoch: 10\t i: 301\t Loss: 0.0051413098890334364\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 10\t Accuracy: 82.54%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 11\t i: 1\t Loss: 6.690988689661026e-05\n",
            "Epoch: 11\t i: 101\t Loss: 0.0034572756476700306\n",
            "Epoch: 11\t i: 201\t Loss: 0.0037953707240521908\n",
            "Epoch: 11\t i: 301\t Loss: 0.004884103951975703\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 11\t Accuracy: 82.59%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 12\t i: 1\t Loss: 2.4554800242185592e-05\n",
            "Epoch: 12\t i: 101\t Loss: 0.00365013793297112\n",
            "Epoch: 12\t i: 201\t Loss: 0.0025454652681946755\n",
            "Epoch: 12\t i: 301\t Loss: 0.003285651985555887\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 12\t Accuracy: 83.12%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 13\t i: 1\t Loss: 1.6296878457069396e-05\n",
            "Epoch: 13\t i: 101\t Loss: 0.0016726381983608008\n",
            "Epoch: 13\t i: 201\t Loss: 0.0010279268734157084\n",
            "Epoch: 13\t i: 301\t Loss: 0.0014041274935007095\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 13\t Accuracy: 82.91%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 14\t i: 1\t Loss: 6.232529878616333e-06\n",
            "Epoch: 14\t i: 101\t Loss: 0.001472476799041033\n",
            "Epoch: 14\t i: 201\t Loss: 0.000963038221001625\n",
            "Epoch: 14\t i: 301\t Loss: 0.001181949533522129\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 14\t Accuracy: 83.45%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 15\t i: 1\t Loss: 5.031976848840713e-06\n",
            "Epoch: 15\t i: 101\t Loss: 0.0005547310709953309\n",
            "Epoch: 15\t i: 201\t Loss: 0.0008217993471771478\n",
            "Epoch: 15\t i: 301\t Loss: 0.0007867886684834957\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 15\t Accuracy: 84.33%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 16\t i: 1\t Loss: 7.06009566783905e-07\n",
            "Epoch: 16\t i: 101\t Loss: 0.0004845772236585617\n",
            "Epoch: 16\t i: 201\t Loss: 0.00039420152828097344\n",
            "Epoch: 16\t i: 301\t Loss: 0.0004851732570677996\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 16\t Accuracy: 83.28999999999999%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 17\t i: 1\t Loss: 2.1349579095840456e-05\n",
            "Epoch: 17\t i: 101\t Loss: 0.0011453537158668042\n",
            "Epoch: 17\t i: 201\t Loss: 0.0010079578049480916\n",
            "Epoch: 17\t i: 301\t Loss: 0.0011103831157088279\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 17\t Accuracy: 82.69999999999999%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 18\t i: 1\t Loss: 4.218563437461853e-06\n",
            "Epoch: 18\t i: 101\t Loss: 0.002125742603093386\n",
            "Epoch: 18\t i: 201\t Loss: 0.0029896444752812385\n",
            "Epoch: 18\t i: 301\t Loss: 0.0020998373590409756\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 18\t Accuracy: 82.53%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 19\t i: 1\t Loss: 1.623740792274475e-05\n",
            "Epoch: 19\t i: 101\t Loss: 0.00226621138304472\n",
            "Epoch: 19\t i: 201\t Loss: 0.001785777159035206\n",
            "Epoch: 19\t i: 301\t Loss: 0.0015377157367765903\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 19\t Accuracy: 83.36%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 20\t i: 1\t Loss: 6.303925067186355e-06\n",
            "Epoch: 20\t i: 101\t Loss: 0.0015654152482748032\n",
            "Epoch: 20\t i: 201\t Loss: 0.0014600501470267773\n",
            "Epoch: 20\t i: 301\t Loss: 0.0011031338535249233\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 20\t Accuracy: 83.28%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 21\t i: 1\t Loss: 1.2145191431045532e-06\n",
            "Epoch: 21\t i: 101\t Loss: 0.0008916476238518954\n",
            "Epoch: 21\t i: 201\t Loss: 0.0009370591379702091\n",
            "Epoch: 21\t i: 301\t Loss: 0.0013529909010976554\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 21\t Accuracy: 82.80999999999999%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 22\t i: 1\t Loss: 5.508042871952057e-06\n",
            "Epoch: 22\t i: 101\t Loss: 0.0009243412092328072\n",
            "Epoch: 22\t i: 201\t Loss: 0.0009680899158120155\n",
            "Epoch: 22\t i: 301\t Loss: 0.0008344086781144143\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 22\t Accuracy: 82.96%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 23\t i: 1\t Loss: 4.0920078754425047e-07\n",
            "Epoch: 23\t i: 101\t Loss: 0.0007998912520706654\n",
            "Epoch: 23\t i: 201\t Loss: 0.0005069150105118752\n",
            "Epoch: 23\t i: 301\t Loss: 0.0004492338951677084\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 23\t Accuracy: 83.84%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 24\t i: 1\t Loss: 1.1576637625694274e-06\n",
            "Epoch: 24\t i: 101\t Loss: 0.0003525559790432453\n",
            "Epoch: 24\t i: 201\t Loss: 0.00026855600625276565\n",
            "Epoch: 24\t i: 301\t Loss: 0.0001627964749932289\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 24\t Accuracy: 84.46000000000001%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 25\t i: 1\t Loss: 3.2963603734970094e-07\n",
            "Epoch: 25\t i: 101\t Loss: 6.954505294561386e-05\n",
            "Epoch: 25\t i: 201\t Loss: 5.38664273917675e-05\n",
            "Epoch: 25\t i: 301\t Loss: 7.854221016168594e-05\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 25\t Accuracy: 84.57000000000001%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 26\t i: 1\t Loss: 1.2888014316558837e-07\n",
            "Epoch: 26\t i: 101\t Loss: 3.691365197300911e-05\n",
            "Epoch: 26\t i: 201\t Loss: 2.5990396738052367e-05\n",
            "Epoch: 26\t i: 301\t Loss: 2.7376119047403334e-05\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 26\t Accuracy: 84.63000000000001%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 27\t i: 1\t Loss: 1.3694912195205689e-07\n",
            "Epoch: 27\t i: 101\t Loss: 1.3912901282310485e-05\n",
            "Epoch: 27\t i: 201\t Loss: 1.7146941274404525e-05\n",
            "Epoch: 27\t i: 301\t Loss: 1.831232011318207e-05\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 27\t Accuracy: 84.76%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 28\t i: 1\t Loss: 6.300956010818482e-08\n",
            "Epoch: 28\t i: 101\t Loss: 1.6245394945144654e-05\n",
            "Epoch: 28\t i: 201\t Loss: 1.1926978826522826e-05\n",
            "Epoch: 28\t i: 301\t Loss: 1.1422343552112579e-05\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 28\t Accuracy: 84.83000000000001%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 29\t i: 1\t Loss: 2.3736059665679932e-07\n",
            "Epoch: 29\t i: 101\t Loss: 9.895145893096924e-06\n",
            "Epoch: 29\t i: 201\t Loss: 1.0296516120433807e-05\n",
            "Epoch: 29\t i: 301\t Loss: 8.990153670310974e-06\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 29\t Accuracy: 84.74000000000001%\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 30\t i: 1\t Loss: 8.445978164672852e-08\n",
            "Epoch: 30\t i: 101\t Loss: 1.085670292377472e-05\n",
            "Epoch: 30\t i: 201\t Loss: 1.3997826725244522e-05\n",
            "Epoch: 30\t i: 301\t Loss: 1.0262824594974518e-05\n",
            "\n",
            "-----------------------------\n",
            "\n",
            "Epoch: 30\t Accuracy: 84.88%\n",
            "\n",
            "-----------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqdv7DNaHAbI",
        "colab_type": "text"
      },
      "source": [
        "# Save Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UPUjojBAZeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1a754ae6-4c10-4a69-83c7-177b48c92e81"
      },
      "source": [
        "# Save Trained Model\n",
        "torch.save(model, \"ResNet-18.pth\")\n",
        "torch.save(model.state_dict(), \"ResNet-18-state-dict.pth\")\n",
        "print(\"Saved ResNet Model...\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved ResNet Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type ResidualBlock. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}