{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "# transform= transfoms.ToTensor [Read the mnist data as torch tensors]\n",
    "train_data = dsets.MNIST(root=\"./dataset/\",\n",
    "                        train = True,\n",
    "                        transform = transforms.ToTensor(),\n",
    "                        download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of Training Dataset\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]), tensor(5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First element in list\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of one image\n",
    "train_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label for one image\n",
    "train_data[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert torch tensor to numpy array\n",
    "train_data[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image using numpy array\n",
    "img = train_data[0][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get True Image Label\n",
    "label = np.asarray(train_data[0][1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"True Label: \" + str(label));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test Data\n",
    "test_data = dsets.MNIST(root=\"./dataset/\",\n",
    "                       train = False,\n",
    "                       transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First image in test dataset\n",
    "test_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First test image\n",
    "img = test_data[0][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First test label\n",
    "label = test_data[0][1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Test Label: \" + str(label));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 100\n",
    "\n",
    "# Num. of Iterations\n",
    "num_iters = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Num epochs\n",
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Iterable Training Dataset Loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset= train_data,\n",
    "                                          batch_size= batch_size,\n",
    "                                          shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that train_loader is iterable\n",
    "import collections\n",
    "\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Iterable Test Dataset Loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset= test_data,\n",
    "                                          batch_size= batch_size,\n",
    "                                          shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that test_loader is iterable\n",
    "isinstance(test_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Class\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # define super to inherit from nn.Module\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # define linear function where input_dim: \"x\" and output_dim: \"y\"\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    # Forward Pass\n",
    "    # Input: values in \"x\"\n",
    "    # Return: estimated value of \"y\" i.e. \"y_hat\"\n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image Dimensions\n",
    "input_dim = 28*28\n",
    "\n",
    "# Output Dimensions: 10 classes\n",
    "output_dim = 10\n",
    "\n",
    "# Instantiate the Model\n",
    "model = LogisticRegressionModel(input_dim=input_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss Criterion\n",
    "# Computes Softmax and Crossentropy Loss\n",
    "criteria = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "lr = 0.01\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x11cf82e08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Parameters\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 784])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FC1 Parameters; \"alpha\"\n",
    "list(model.parameters())[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FC1 Bias: \"beta\"\n",
    "list(model.parameters())[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anujdutt/miniconda3/envs/deeplearning/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500\t Loss: 0.8442320823669434\t Accuracy: 84%\n",
      "Iteration: 1000\t Loss: 0.6114340424537659\t Accuracy: 86%\n",
      "Iteration: 1500\t Loss: 0.637068510055542\t Accuracy: 87%\n",
      "Iteration: 2000\t Loss: 0.46675723791122437\t Accuracy: 88%\n",
      "Iteration: 2500\t Loss: 0.4421962797641754\t Accuracy: 88%\n",
      "Iteration: 3000\t Loss: 0.4480551481246948\t Accuracy: 89%\n",
      "Iteration: 3500\t Loss: 0.445093035697937\t Accuracy: 89%\n",
      "Iteration: 4000\t Loss: 0.31390073895454407\t Accuracy: 89%\n",
      "Iteration: 4500\t Loss: 0.44040313363075256\t Accuracy: 89%\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Go through all 60,000 train images\n",
    "    for i, (image,label) in enumerate(train_loader):\n",
    "        # Define Training Inputs and Labels\n",
    "        # Variable has \"requires_grad = True\" by default\n",
    "        # images and labels are already torch tensors, no need to define again\n",
    "        inputs = Variable(image.view(-1,28*28))\n",
    "        labels = Variable(label)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters every epoch to avoid gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Execute forward pass to get predicted labels\n",
    "        y_hat = model(inputs)\n",
    "        \n",
    "        # Calculate the loss: Softmax -> Crossentropy Loss\n",
    "        loss = criteria(y_hat,labels)\n",
    "        \n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the Parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter%500 == 0:\n",
    "            # Calculate Accuracy of Model\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Iterate through test dataset to get accuracy\n",
    "            for images,labels in test_loader:\n",
    "                # Load Images\n",
    "                inputs = Variable(images.view(-1,28*28))\n",
    "                \n",
    "                # Get predicted outputs\n",
    "                y_hat = model(inputs)\n",
    "                \n",
    "                # Get predictions from max probb value\n",
    "                _, predicted = torch.max(y_hat.data,1)\n",
    "                \n",
    "                # Total labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            print(\"Iteration: {0}\\t Loss: {1}\\t Accuracy: {2}%\".format(iter,loss.data[0],accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
